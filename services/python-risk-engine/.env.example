# Application Settings
PROJECT_NAME="Python Engine Service"
API_V1_STR="/api/v1"

# Server Configuration
HOST=0.0.0.0
PORT=5000
DEBUG=False
WORKERS=4
THREADS=2

# CORS Configuration
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8000"]

# Database Configuration
POSTGRES_SERVER=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=python_engine
DATABASE_URI=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_SERVER}:5432/${POSTGRES_DB}

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=your-redis-password
REDIS_DB=0

# Security
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=1440  # 24 hours

# Logging
LOG_LEVEL="INFO"

# AI Model Configuration
MODEL_PATH="./models"

# Redis Configuration (for caching and rate limiting)
REDIS_HOST="localhost"
REDIS_PORT=6379
REDIS_DB=0

# External Services
OPENAI_API_KEY="your-openai-api-key"

# Monitoring
SENTRY_DSN=""  # Add your Sentry DSN for error tracking

# Feature Flags
ENABLE_ANALYTICS=False
ENABLE_CACHING=True
ENABLE_RATE_LIMITING=True
